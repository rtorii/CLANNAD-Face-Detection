# CLANNAD顔認識

**説明：**

このプログラムは、画像からCLANNADというアニメのキャラクターを認識し、どのキャラクターが画像のどの位置にいるかを出力します。CLANNADを選んだ理由は、どのキャラクターも似たような目の形をしていて、正確に認識することが他のアニメと比べて難しいと思ったからです。スクリーンショットでCLANNAD（1話から22話）の画像を集め、それを元に[公式ホームページ](https://www.tbs.co.jp/clannad/clannad1/04chara/chara.html)に載っているキャラクター8人を認識するモデルを作成し、使用します。

  | 入力画像 | 出力画像 |
  | ------ | ------ |
  | ![くらなど](https://user-images.githubusercontent.com/52717342/175796835-4bb0178b-7631-4cb9-b43f-c0a9670c3118.jpeg) | ![f2c533a00ecb95ead668ed36a7c42963b3d02ce64691bf10c2b779dd](https://user-images.githubusercontent.com/52717342/175796837-a6d859ba-1072-410f-a5b4-cf936ebfec58.jpeg) |
  | © VisualArt's/Key/光坂高校演劇部 ／引用元: [RENOTE](https://renote.jp/articles/11191) |  |




**ファイル：**

- ```lbpcascade_animeface.xml``` - アニメの顔を検出する際に使用する[カスケードファイル](https://github.com/nagadomi/lbpcascade_animeface)。
- ```face.py``` - ```lbpcascade_animeface.xml```を使用し、CLANNADの画像からキャラクターの顔画像を切り抜き、保存するプログラム。
- ```da.py``` - 訓練用画像をぼかしたり、明るさを変えるなどして、訓練用画像の枚数を増やすプログラム。
- ```train.py``` - モデルを作成し、モデルをテスト用画像に対しテストするプログラム。
- ```model_200_160_80_epoch30_30.h5``` - 顔画像からCLANNADのキャラクターを認識するモデル。
- ```test.py``` - 画像を受け入れ、画像から認識したキャラクターの名前と位置を含む画像を出力するプログラム。
- ```app.py``` - Streamlitを使用し、```test.py```をWebアプリにするプログラム。
  - Webアプリのリンク: https://rtorii-clannad-face-detection-app-6furpy.streamlitapp.com/


# 順番にしたこと

    1. キャラクターの顔画像を集め、キャラクターごとに分類する。
    2. 訓練用画像の枚数を増やす。
    3. モデル作成。
    4. モデルをテスト用画像でテストする。
    5. 画像にどのキャラクターが、画像内のどの位置にいるかを出力するプログラムを作成。
    6. Streamlitを使用し、プログラムをWebアプリとして公開。

1 .  **キャラクターの顔画像を集め、キャラクターごとに分類する。```face.py```**
- スクリーンショットでCLANNAD（1話から22話）の画像を集め、画像から顔を検出（```lbpcascade_animeface.xml```を使用）し、保存します。
- 手作業で顔画像をキャラクターごとに分類し、キャラクターごとに別のフォルダーに保存します。主人公の岡崎朋也の顔画像が最も多く集まりました。
- ```split-folder```というライブラリを使用し、画像を訓練用とテスト用（8:2の比率）に分けます。

    |  キャラクター   |  集めた顔画像の枚数（訓練用 : テスト用）   |  キャラクター   | 集めた顔画像の枚数（訓練用 : テスト用）    |
    | --- | --- | --- | --- | 
    |   伊吹風子  |   133 (106 : 27)  |  一ノ瀬ことみ   | 127 (101 : 26)   |
    |   藤林杏  |   96 (76 : 20)  |   古川渚  |  229 (184 : 45)   |
    |   藤林涼  |  88 (70 : 18)   |  岡崎朋也   |  286 (231 : 55)   | 
    |   坂上智代  |  128 (102 : 26)  |  春原陽平   |  119 (95 : 24)  |

    ※ 春原陽平はCLANNAD ～After Story～ （CLANNAD第2期）では黒髪のシーンがありますが、CLANNAD（第1期）では金髪のため、今回は金髪の春原陽平の画像を使用します。

2 . **訓練用画像の枚数を増やす：データオーギュメンテーション　```da.py```**
- 訓練用画像1枚につき、3つの異なるぼかし度の画像を作成します。それに加え、それぞれの画像に対し、5つの異なる明るさの画像を作成します。そのため、訓練用画像の枚数は、元と比べ、3 x 5 = 15倍になります。
- 8人のキャラクターの訓練用画像の合計は14,475枚となりました。

    |  キャラクター   |  訓練用画像の枚数    |  キャラクター   | 訓練用画像の枚数     |
    | --- | --- | --- | --- | 
    |   伊吹風子  |   1590  |  一ノ瀬ことみ   | 1515    |
    |   藤林杏  |   1140  |   古川渚  |  2760   |
    |   藤林涼  |  1050   |  岡崎朋也   |  3465   | 
    |   坂上智代  |  1530   |  春原陽平   |  1425   |


3 . **モデル作成。 ```train.py```**
- KerasでSequentialモデル（4層のニューラルネットワーク）を作成します。そして100x100のサイズにリサイズした訓練用画像全てに対して学習させます。リサイズした理由は、```lbpcascade_animeface.xml```で切り取られた画像は正方形ですが、サイズが同じとは限らないためです。
- モデルはそれぞれのマスのRGB情報（100x100x3 = 30000）を入力として受け入れ、8つの出力層（8人のキャラクターを認識するため）があります。一番出力値が高いキャラクターを画像のキャラクターとして認識します。
- エポック数を30（過学習しない程度）に設定しました。

    ```
    Epoch 21/30
    483/483 [==============================] - 6s 12ms/step - loss: 0.1139 - accuracy: 0.9727
    Epoch 22/30
    483/483 [==============================] - 6s 12ms/step - loss: 0.1058 - accuracy: 0.9719
    Epoch 23/30
    483/483 [==============================] - 7s 14ms/step - loss: 0.0948 - accuracy: 0.9771
    Epoch 24/30
    483/483 [==============================] - 7s 14ms/step - loss: 0.0843 - accuracy: 0.9800
    Epoch 25/30
    483/483 [==============================] - 6s 13ms/step - loss: 0.0765 - accuracy: 0.9825
    Epoch 26/30
    483/483 [==============================] - 6s 12ms/step - loss: 0.0761 - accuracy: 0.9813
    Epoch 27/30
    483/483 [==============================] - 6s 12ms/step - loss: 0.0686 - accuracy: 0.9844
    Epoch 28/30
    483/483 [==============================] - 6s 12ms/step - loss: 0.0636 - accuracy: 0.9843
    Epoch 29/30
    483/483 [==============================] - 6s 13ms/step - loss: 0.0574 - accuracy: 0.9869
    Epoch 30/30
    483/483 [==============================] - 6s 13ms/step - loss: 0.0513 - accuracy: 0.9882
    ```
4 . **モデルをテスト用画像でテストする。```train.py```**
- モデルをテスト用画像でテストした結果、全体の正解率は226 / 241 = 93.8%でした。
- 岡崎朋也は、訓練用画像の枚数が一番多かったためか、全てのテスト用画像で正確に認識しました。
- 姉妹の藤林杏と藤林涼が同じ髪色で、訓練用画像の枚数が他のキャラクターと比べ少なかったこともあってか、正解率が他のキャラクターより低い結果となりました。


  |  キャラクター   |   正解数  |  テスト用画像の枚数   | 正解率   | キャラクター   |  正解数   |  テスト用画像の枚数   | 正解率   |
  | --- | --- | --- | --- | --- | --- | --- | --- | 
  |   伊吹風子  |  26   |   27  |  96.3%   |  一ノ瀬ことみ   |  24   | 26   |  92.3%  | 
  |  藤林杏   |   17  |  20   |   85%  |  古川渚   |  43   |  45   |  95.6%   | 
  |  藤林涼   |  15   |   18  |   83.3%  |   岡崎朋也  |  55   |  55   |   100%    | 
  |  坂上智代   |  23   |  26   |  88.5%  |  春原陽平   |  23   |  24   |  95.8%   | 

5 . **画像にどのキャラクターが、画像内のどの位置にいるかを出力するプログラムを作成。```test.py```**

  アニメの画像（出典元が加工を許可していないもの）を加工し、インターネットに掲載することは著作権を侵害するという記事を見たので、今回は、白色の背景にキャラクターの名前と位置を示す画像を出力しました。  

**プログラムの手順：**
1. ```lbpcascade_animeface.xml```を使用し、画像から顔を認識する。
2. 認識した顔それぞれをモデルに入力し、出力の中で最も値が高いキャラクターを画像のキャラクターとして認識する。
3. 認識したキャラクターの名前と位置を示す画像を出力する。

  | 入力画像 | 出力画像 |
  | ------ | ------ |
  | ![5aca841a5e7f9cb1fa2fe36d74f51c486e17d7d2d0715424effb70ab](https://user-images.githubusercontent.com/52717342/175799918-d6354880-c3ba-4f1b-829c-94e07b80b43e.jpeg) | ![f45514849387e57cca1283ba6311a07841285ef809d10fd42e28842f](https://user-images.githubusercontent.com/52717342/175799923-161d704f-fdc0-4945-ad04-cc6cd7823cb7.jpeg) |
  | © VisualArt's/Key/光坂高校演劇部 ／引用元: [アニメミル](https://animemiru.jp/articles/7675/) |  |

- 目をつぶっている古川渚と泣いている春原陽平を認識できました。坂上智代は横顔のため、```lbpcascade_animeface.xml```は顔として認識しません。

| 入力画像 | 出力画像 |
| ------ | ------ |
| ![25a02d32019f1987c8fa9a83b159cfa6b891afbe2346d2d3122d07b10cc1766f _SX1080_](https://user-images.githubusercontent.com/52717342/175796378-d3f18259-b42b-45ee-ae19-a43b3e3724a6.jpg) | ![696b9da8dc6eac7d29d7a1c5d4db7dd0f19f2c69e7944f40a04813ec](https://user-images.githubusercontent.com/52717342/175796921-2646e6b2-0125-444b-9e34-ff99aa62e089.jpeg) |
| © VisualArt's/Key/光坂高校演劇部 ／引用元: [Amazon](https://www.amazon.co.jp/CLANNAD-AFTER-STORY%E3%80%90TBS%E3%82%AA%E3%83%B3%E3%83%87%E3%83%9E%E3%83%B3%E3%83%89%E3%80%91/dp/B00FYKXTGS) |  |

- 姉妹の藤林涼と藤林杏を認識。

| 入力画像 | 出力画像 |
| ------ | ------ |
| ![t02200154_0342024012866838688](https://user-images.githubusercontent.com/52717342/175796415-5c420ac1-446b-4d48-89a6-528d5ed6f1c9.jpeg) | ![5c3ed7ae87c874586f77c27bedb77fd96842877d04f4996b4f4db944](https://user-images.githubusercontent.com/52717342/175796419-63f97fc3-b029-4b31-85af-dd06d8694dc9.jpeg) |
| © VisualArt's/Key/光坂高校演劇部 ／引用元: [ameblo](https://ameblo.jp/i-was-me/entry-11786945737.html) |  |

6 . **Streamlitで、プログラムをWebアプリとして公開。**
- Webアプリのリンク: https://rtorii-clannad-face-detection-app-6furpy.streamlitapp.com/

**Webアプリの使用方法:**
1.  CLANNADのキャラクターの顔が写っている画像をアップロードします。
2.  ```Process```ボタンを押すと出力画像が表示されます。

| ホームページ | 
| ------ |
| <img width="1439" alt="Screen Shot 2022-06-26 at 13 20 10" src="https://user-images.githubusercontent.com/52717342/175799260-cb8ab7e3-ba52-4e46-919c-396fdcfbf745.png"> |


06/26/22に作成。

<!-- Epoch 1/30
483/483 [==============================] - 6s 12ms/step - loss: 1.6552 - accuracy: 0.4286
Epoch 2/30
483/483 [==============================] - 6s 11ms/step - loss: 1.1671 - accuracy: 0.6345
Epoch 3/30
483/483 [==============================] - 6s 12ms/step - loss: 0.8990 - accuracy: 0.7293
Epoch 4/30
483/483 [==============================] - 6s 12ms/step - loss: 0.7456 - accuracy: 0.7774
Epoch 5/30
483/483 [==============================] - 6s 11ms/step - loss: 0.6332 - accuracy: 0.8175
Epoch 6/30
483/483 [==============================] - 6s 11ms/step - loss: 0.5515 - accuracy: 0.8398
Epoch 7/30
483/483 [==============================] - 6s 12ms/step - loss: 0.4826 - accuracy: 0.8631
Epoch 8/30
483/483 [==============================] - 6s 12ms/step - loss: 0.4339 - accuracy: 0.8770
Epoch 9/30
483/483 [==============================] - 6s 12ms/step - loss: 0.3811 - accuracy: 0.8913
Epoch 10/30
483/483 [==============================] - 6s 12ms/step - loss: 0.3388 - accuracy: 0.9064
Epoch 11/30
483/483 [==============================] - 6s 12ms/step - loss: 0.3064 - accuracy: 0.9171
Epoch 12/30
483/483 [==============================] - 6s 12ms/step - loss: 0.2756 - accuracy: 0.9235
Epoch 13/30
483/483 [==============================] - 6s 12ms/step - loss: 0.2472 - accuracy: 0.9330
Epoch 14/30
483/483 [==============================] - 6s 12ms/step - loss: 0.2201 - accuracy: 0.9411
Epoch 15/30
483/483 [==============================] - 6s 12ms/step - loss: 0.2011 - accuracy: 0.9460
Epoch 16/30
483/483 [==============================] - 6s 12ms/step - loss: 0.1830 - accuracy: 0.9530
Epoch 17/30
483/483 [==============================] - 6s 12ms/step - loss: 0.1664 - accuracy: 0.9572
Epoch 18/30
483/483 [==============================] - 6s 12ms/step - loss: 0.1494 - accuracy: 0.9636
Epoch 19/30
483/483 [==============================] - 6s 12ms/step - loss: 0.1412 - accuracy: 0.9620
Epoch 20/30
483/483 [==============================] - 6s 12ms/step - loss: 0.1228 - accuracy: 0.9687 -->

